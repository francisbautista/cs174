{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS174B: Word2Vec Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re, nltk, gensim\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tweets sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/airline-sentiment.csv',  encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153    False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156    False   finalized                   3     2/25/15 10:01   \n",
       "3  681448158    False   finalized                   3      2/25/15 3:05   \n",
       "4  681448159    False   finalized                   3      2/25/15 5:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  \n",
       "3  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "4  2/24/15 11:14  5.703010e+17            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the text to do the following:\n",
    "\n",
    "-Normalize every word to lower case.\n",
    "\n",
    "-Remove punctuation and retain only numbers and alphabets.\n",
    "\n",
    "-Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^0-9a-z]+',' ',text)\n",
    "    split = text.split()\n",
    "    stopped = [i for i in split if i not in stop]\n",
    "    joined=' '.join(stopped)\n",
    "    return(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the unnecessary columns (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"airline_sentiment\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                        virginamerica dhepburn said\n",
       "1          positive  virginamerica plus added commercials experienc...\n",
       "2           neutral  virginamerica today must mean need take anothe...\n",
       "3          negative  virginamerica really aggressive blast obnoxiou...\n",
       "4          negative                 virginamerica really big bad thing"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of words similar to the TFIDF exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist=[]\n",
    "for i in range(len(df)):\n",
    "    wordlist.append(df['text'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['virginamerica', 'dhepburn', 'said'],\n",
       " ['virginamerica', 'plus', 'added', 'commercials', 'experience', 'tacky'],\n",
       " ['virginamerica', 'today', 'must', 'mean', 'need', 'take', 'another', 'trip']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Time\n",
    "\n",
    "Build the Word2Vec model. Define the vector size, context window size to look into, and the minimum count of a word for it to be eligible to have a word vector\n",
    "- size represents the size (dimension) of word vectors.\n",
    "- window represents the context size of words that would be considered.\n",
    "- min_count specifies the minimum frequency based on which a word is considered.\n",
    "- sg represents whether skip-gram used (when sg=1) or CBOW (when sg = 0) used.\n",
    "- alpha is the learning rate (which we'll discuss next week on neural nets proper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Other papers did not report an experiment on embedding dimension size. They are all using an arbitrary dimension on the order of hundreds (100 and 300 are used more frequently). The lack of experiments for embedding size implies that the performance is not very sensitive to this parameter and only the order of magnitude matters, and also other aspects of the model architecture are more important to investigate.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(size=100,window=5,min_count=30, sg=0, alpha = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(wordlist)\n",
    "model.corpus_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['virginamerica', 'said', 'plus', 'experience', 'today', 'must', 'mean', 'need', 'take', 'another', 'trip', 'really', 'amp', 'little', 'big', 'bad', 'thing', 'seriously', 'would', 'pay', '30', 'flight', 'seats', 'flying', 'yes', 'every', 'time', 'fly', 'go', 'away', 'missed', 'without', 'https', 'co', 'well', 'amazing', 'arrived', 'hour', 'early', 'good', 'know', 'second', 'cause', '10', '24', 'lt', '3', 'pretty', 'much', 'better', 'great', 'deal', 'already', '2nd', 'even', '1st', 'yet', 'u', 'travel', 'http', 'thanks', 'sfo', 'schedule', 'still', 'mia', 'first', 'country', 'lax', 'mco', 'heard', 'nothing', 'things', 'virgin', 'flew', 'nyc', 'last', 'week', 'sit', 'seat', 'due', 'two', 'either', 'help', 'awesome', 'bos', 'fll', 'please', 'want', 'may', 'three', 'times', 'available', 'love', 'feel', 'making', 'gt', 'las', 'non', 'stop', 'soon', 'guys', 'friends', 'gave', 'free', 'status', 'weeks', 'called', 'response', 'happened', '2', 'ur', 'food', 'options', 'least', 'say', 'site', 'able', 'anything', 'next', '6', 'hrs', 'fail', 'miss', 'together', 'get', 'cold', 'air', 'ewr', 'middle', 'hi', 'cool', 'birthday', 'add', 'name', 'booking', 'problems', 'hours', 'club', 'online', 'left', 'iad', 'one', 'answering', 'f', 'number', 'return', 'phone', 'call', 'use', 'service', 'option', 'news', 'could', 'start', 'flights', 'end', 'year', 'via', 'nice', 'rt', 'way', 'best', 'ever', 'done', 'airline', 'around', 'book', 'support', 'working', 'beyond', 'hey', 'hard', 'getting', 'account', 'upgrade', 'ticket', 'moved', 'new', 'city', 'leaving', 'dallas', 'feb', 'reason', 'rock', 'wow', 'night', 'think', 'supposed', 'minutes', 'ago', 'website', 'though', 'wish', 'atlanta', 'la', 'lga', 'trying', 'since', 'never', 'thx', 'let', 'us', '4', 'sorry', 'dca', 'tried', 'check', 'someone', 'hold', '40', '50', 'earlier', 'tonight', '11', 'award', 'everything', 'fine', 'lost', 'bag', 'change', 'reservation', 'credit', 'card', 'fee', 'customer', 'team', 'booked', 'baggage', 'needs', 'plane', 'crew', 'airlines', 'like', 'yall', 'sat', 'morning', 'correct', '000', 'different', 'policy', 'media', 'bags', 'going', 'speak', 'human', 'asap', 'thank', 'southwestair', 'jetblue', 'member', 'im', '100', 'delayed', 'late', 'cancelled', 'four', 'business', 'wife', 'bring', 'using', 'share', 'life', 'happens', 'home', 'back', 'yeah', 'points', 'tv', 'disappointed', 'flightled', 'went', 'jfk', 'landed', 'friendly', 'mobile', 'passengers', 'leave', 'told', 'class', 'find', 'anyone', 'direct', 'layover', 'vegas', 'bought', 'people', 'customerservice', 'line', 'hung', 'info', 'scheduled', 'changed', 'weather', 'looks', 'lots', 'come', 'phl', 'horrible', 'flown', 'easy', 'helpful', 'rep', 'front', 'right', 'b', 'c', 'running', 'gate', 'waited', '2015', 'totally', 'problem', 'min', 'delay', 'connecting', 'seems', 'long', 'san', 'provide', '9', 'wait', 'calling', 'completely', 'month', 'customers', 'process', 'link', 'tsa', 'pre', 'terrible', 'hotel', 'assistance', 'yesterday', 'give', 'longer', 'pls', 'always', 'buy', 'frustrated', 'paying', 'extra', 'luggage', 'might', 'world', 'takes', 'flt', 'monday', 'cant', 'staff', 'super', 'paid', 'offer', 'sad', 'question', 'possible', 'giving', 'dc', 'work', 'understand', 'dm', 'answer', 'w', 'kids', '1', 'priority', 'boarding', 'checking', 'tickets', 'happy', 'coming', 'dfw', 'friday', 'error', 'contact', 'minute', 'reschedule', 'fix', 'got', 'checked', 'email', 'tomorrow', 'unacceptable', 'flighted', 'stuck', 'offered', 'look', 'agent', 'airport', 'plans', 'austin', 'route', 'reply', 'waiting', 'checkin', 'desk', 'open', 'luv', 'show', 'united', 'follow', 'many', 'r', 'worse', 'respond', 'money', 'stranded', 'landing', 'southwest', 'days', 'confirmation', 'claim', '8', 'rebook', 'gold', 'lot', 'see', 'worst', 'wrong', 'issue', 'missing', 'lose', 'suck', 'flightlation', 'boston', 'guy', 'high', 'quick', 'apparently', 'sitting', 'sent', 'keep', 'ny', 'pilots', 'job', 'snow', 'area', 'afternoon', 'row', 'mechanical', 'handle', 'twitter', 'charged', 'refund', 'access', 'received', 'broken', 'looking', 'forward', 'rescheduled', 'gonna', 'land', 'cost', '800', 'report', 'attendant', 'something', 'departure', 'fun', 'updates', 'helping', 'passenger', 'destination', 'entire', 'confirmed', 'treat', 'wtf', 'inconvenience', 'full', 'place', 'instead', 'makes', 'cabin', 'pilot', 'tell', 'past', 'husband', 'came', 'despite', 'gives', 'delays', 'says', 'expect', '5', 'safety', 'day', 'wanted', 'newark', 'hope', 'probably', 'board', 'standby', 'helped', 'absolutely', 'ready', 'old', 'less', 'half', 'price', 'round', 'fare', 'made', 'taking', 'care', 'mileage', 'several', 'americanair', 'glad', 'took', 'years', 'try', 'purchase', 'hoping', 'carry', 'empty', 'space', 'spoke', 'loyal', 'family', 'ok', 'currently', 'car', 'sucks', 'cust', 'child', 'chance', 'joke', 'also', 'tix', 'send', 'request', 'ceo', 'planes', 'thought', 'computer', '15', 'cannot', 'guess', 'make', 'address', 'app', 'set', 'system', 'charge', 'tweet', 'houston', 'finally', 'future', 'poor', '1k', 'group', 'room', 'sure', '12', 'shit', 'stay', 'wifi', 'saying', 'point', 'part', 'whole', 'person', 'calls', 'ask', 'flighting', 'luck', 'lol', 'storm', 'complete', 'fees', 'philly', 'months', 'update', 'reps', 'actually', 'word', 'lack', 'ord', 'connections', 'international', 'orlando', 'mins', 'boarded', 'issues', 'oh', 'ridiculous', 'case', 'voucher', 'company', 'maybe', 'pass', 'given', 'miami', 'drive', 'explain', 'talk', 'almost', 'ppl', 'flightr', 'platinum', 'run', 'agents', 'rude', 'overnight', 'hr', 'iah', 'taken', 'used', 'details', 'charlotte', 'form', 'ground', 'else', 'appreciate', 'tarmac', 'enough', 'denver', 'put', 'found', 'supervisor', 'thru', 'connection', 'upset', 'services', 'employees', 'mom', '7', 'miles', 'american', 'rather', 'telling', 'delta', 'attendants', 'seem', 'believe', 'bc', 'record', 'asking', 'read', 'everyone', 'ua', 'aircraft', 'knew', 'winter', 'reach', 'hear', 'mine', 'apology', 'goes', 'zero', 'date', 'members', 'weekend', 'asked', 'held', '25', 'message', 'complaint', 'awful', 'jet', 'atl', 'traveling', 'works', 'communication', 'far', 'top', 'unitedairlines', 'kudos', 'extremely', 'real', 'clothes', 'leg', 'chicago', 'lounge', 'okay', 'load', 'terminal', 'arrival', '20', 'information', 'confirm', 'vacation', 'nope', 'sleep', 'compensation', 'original', 'happen', 'delivered', 'arrive', 'employee', 'answers', 'clt', 'idea', 'responding', 'frustrating', 'figure', 'counter', 'unfortunately', 'fact', 'needed', 'means', 'bwi', 'pm', 'fixed', 'unable', 'ice', 'phones', 'den', 'fleet', 'spent', 'situation', 'list', 'changes', '200', 'control', 'aa', 'reservations', 'reflight', '45', 'seen', 'tuesday', 'id', 'multiple', 'maintenance', 'friend', 'twice', 'allowed', 'counting', 'rebooked', 'sunday', 'sense', 'hate', 'huge', 'hopefully', 'rdu', 'usairways', 'pick', 'crazy', 'airways', 'gets', 'treated', 'fault', 'sending', 'losing', 'nashville', 'changing', 'switch', 'flightlations', 'dont', 'appreciated', 'hang', 'plan', 'following', 'runway', 'true', 'live', 'busy', 'allow', 'hello', 'relations', 'disconnected', 'water', 'bna', 'kind', 'phx', 'automated', 'companion', 'haha', 'sw', 'holding', 'swa', 'destinationdragons', 'imaginedragons', 'usair', 'blue', 'fleek', 'wall'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8555260, 15367300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(wordlist, total_examples=model.corpus_count, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the wordvector for a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.4645264e-01,  1.7522665e+00,  5.3755965e-02,  2.5623145e+00,\n",
       "       -3.6641023e-01,  1.0455021e+00,  3.1233358e-01, -8.3864528e-01,\n",
       "        1.6878428e+00, -4.5925853e-01,  1.1221740e+00,  1.5017433e+00,\n",
       "       -1.1384646e+00, -1.2850329e+00, -4.8522443e-01, -1.0051377e+00,\n",
       "        1.2366996e+00,  1.0283921e+00,  2.1941327e-03, -3.2236233e-01,\n",
       "        1.2023031e+00,  1.9695036e+00, -5.1865625e-01, -2.9258964e+00,\n",
       "        6.1163485e-01,  1.8918989e+00,  1.5186785e+00, -3.4030903e-02,\n",
       "        6.9862628e-01,  1.4631043e-01,  1.4218019e+00, -3.1243043e+00,\n",
       "       -6.7166120e-01, -2.3415513e+00,  4.3108252e-01,  2.4061044e-01,\n",
       "        7.1815002e-01, -3.2479334e+00,  2.4947050e+00, -5.5266297e-01,\n",
       "        7.9838842e-01,  1.3533766e+00,  8.3027445e-02,  8.5906875e-01,\n",
       "       -2.8035412e+00,  3.1235674e-01,  1.0476404e+00, -1.8752144e-01,\n",
       "       -1.3371296e+00, -1.1365536e+00, -6.5343815e-01, -1.3539853e+00,\n",
       "       -1.8860098e+00, -2.0132370e+00,  2.9466374e+00, -9.1813862e-01,\n",
       "       -1.3251474e+00,  1.2115775e+00, -1.7326905e-01,  2.6537726e+00,\n",
       "        2.4533328e-01, -1.4703680e+00,  5.9314394e-01,  6.9270229e-01,\n",
       "       -1.4996315e+00, -2.0009819e-01,  1.3426120e+00, -6.2410730e-01,\n",
       "       -1.3765836e+00, -1.3127265e+00, -3.4896526e+00, -3.9828318e-01,\n",
       "       -4.0834653e-01,  4.7822407e-01, -1.2388679e+00,  4.3124756e-01,\n",
       "       -6.3117582e-01,  6.7490405e-01, -3.5562155e-01,  1.7812390e+00,\n",
       "        5.7742006e-01,  2.2117012e+00, -3.0014992e-01, -2.3060362e+00,\n",
       "        8.3199508e-02, -1.1006758e+00, -4.7589102e-01, -1.9050823e+00,\n",
       "        8.6405122e-01,  4.1721664e-02,  3.8877692e+00,  5.0215542e-01,\n",
       "        1.2024288e+00,  5.1853311e-01,  1.0564882e+00,  1.1575140e+00,\n",
       "        1.4954260e-01, -1.8644801e+00, -9.0040915e-02, -3.5687773e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity of words are baked into Word2Vec. Use this as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5180526"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('month','year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('years', 0.9994949698448181),\n",
       " ('takes', 0.9994686841964722),\n",
       " ('little', 0.9994019865989685),\n",
       " ('suck', 0.9993892312049866),\n",
       " ('mean', 0.9993865489959717),\n",
       " ('zero', 0.9993835091590881),\n",
       " ('paying', 0.9993681907653809),\n",
       " ('entire', 0.9993562698364258),\n",
       " ('fault', 0.9993394017219543),\n",
       " ('plus', 0.9993321299552917)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see the output of most similar words to the word \"month\", when we run the model for a few number of epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that low epoch count leads to bad model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('years', 0.9994949698448181),\n",
       " ('takes', 0.9994686841964722),\n",
       " ('little', 0.9994019865989685),\n",
       " ('suck', 0.9993892312049866),\n",
       " ('mean', 0.9993865489959717),\n",
       " ('zero', 0.9993835091590881),\n",
       " ('paying', 0.9993681907653809),\n",
       " ('entire', 0.9993562698364258),\n",
       " ('fault', 0.9993394017219543),\n",
       " ('plus', 0.9993321299552917)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(size=100,window=5,min_count=30, sg=0)\n",
    "model.build_vocab(wordlist)\n",
    "model.train(wordlist, total_examples=model.corpus_count, epochs=5)\n",
    "model.most_similar('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
